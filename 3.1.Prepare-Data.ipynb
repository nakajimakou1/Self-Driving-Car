{"nbformat_minor": 1, "cells": [{"source": "# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u53d6\u5f97\nGerman Traffic Sign Recognition Benchmark (GTSRB)", "cell_type": "markdown", "metadata": {}}, {"source": "!wget http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Training_Images.zip", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "!unzip GTSRB_Final_Training_Images.zip", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport csv\nfrom PIL import Image\n\nrootpath = 'GTSRB/Final_Training/Images'\n\nimages = [] # images\nlabels = [] # corresponding labels\n# loop over all 43 classes\nfor c in range(0,43):\n    prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n    gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n    gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n    next(gtReader)\n    # loop over all images in current annotations file\n    for row in gtReader:\n        image = Image.open(prefix + row[0])\n        crop_image = image.crop((int(row[3]),int(row[4]),int(row[5]),int(row[6])))\n        resize_image = crop_image.resize((32,32))\n        images.append(np.asarray(resize_image))\n        labels.append(int(row[7]))\n    gtFile.close()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "print(np.array(images).shape)\nprint(np.array(labels).shape)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# \u30c7\u30fc\u30bf\u306e\u5206\u5272\ntrain, test \u306b\u5206\u5272", "cell_type": "markdown", "metadata": {}}, {"source": "from sklearn.model_selection import train_test_split \n\ntrain_data, test_data, train_label, test_label = train_test_split(np.array(images), np.array(labels), test_size=0.1)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "print('train size:', train_data.shape)\nprint('test size:', test_data.shape)\nprint('train label size:', train_label.shape)\nprint('test label size:', test_label.shape)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# \u30c7\u30fc\u30bf\u306e\u78ba\u8a8d", "cell_type": "markdown", "metadata": {}}, {"source": "!wget https://raw.githubusercontent.com/schiyoda/Self-Driving-Car/master/signnames.csv", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "import csv\n\nf = open('signnames.csv', 'r')\n\nreader = csv.reader(f)\nheader = next(reader)\nsignnames = []\nfor row in reader:\n    signnames.append(row[1])\n\nf.close()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "fig, axs = plt.subplots(9,5, figsize=(15, 30))\nfig.subplots_adjust(hspace = .1, wspace=.1)\naxs = axs.ravel()\nfor i in range(45):\n    if(i < 43):\n        idx = np.where(train_label == i )[0][0]\n        axs[i].imshow(train_data[idx])\n        axs[i].set_title(signnames[i])\n    axs[i].axis('off')", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# \u30c7\u30fc\u30bf\u3092 pickle \u306b\u5909\u63db\u3057\u3066ICOS\u306b\u4fdd\u7ba1", "cell_type": "markdown", "metadata": {}}, {"source": "import pickle\n\ntrain_tpl = (train_data, train_label)\nwith open('training_data.pkl', 'wb') as f:\n    pickle.dump(train_tpl, f)\n    \ntest_tpl = (test_data, test_label)\nwith open('test_data.pkl', 'wb') as f:\n    pickle.dump(test_tpl, f)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "\u4fdd\u7ba1\u5148\u306eICOS\u306ecredential\u3092\u6307\u5b9a", "cell_type": "markdown", "metadata": {}}, {"source": "from ibm_botocore.client import Config\nimport ibm_boto3\n\ncos_credentials={\n  \"apikey\": \"*************\",\n  \"endpoints\": \"*************\",\n  \"iam_apikey_description\": \"*************\",\n  \"iam_apikey_name\": \"*************\",\n  \"iam_role_crn\": \"*************\",\n  \"iam_serviceid_crn\": \"*************\",\n  \"resource_instance_id\": \"*************\"\n}\n\nauth_endpoint = 'https://iam.bluemix.net/oidc/token'\nservice_endpoint = 'https://s3-api.us-geo.objectstorage.softlayer.net'\n\ncos = ibm_boto3.client('s3',\n                         ibm_api_key_id=cos_credentials['apikey'],\n                        ibm_service_instance_id=cos_credentials['resource_instance_id'],\n                         ibm_auth_endpoint=auth_endpoint,\n                         config=Config(signature_version='oauth'),\n                         endpoint_url=service_endpoint)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "\u4fdd\u7ba1\u5148\u306eICOS\u306ebacket\u3092\u6307\u5b9a", "cell_type": "markdown", "metadata": {}}, {"source": "backet = 'xxx'\n\ncos.upload_file(Filename='training_data.pkl',Bucket=backet,Key='training_data.pkl')\ncos.upload_file(Filename='test_data.pkl',Bucket=backet,Key='test_data.pkl')", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3.5", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.5", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}